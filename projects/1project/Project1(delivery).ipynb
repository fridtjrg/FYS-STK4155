{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "246bd8e0",
   "metadata": {},
   "source": [
    "# Fys-stk4155 - Project 1\n",
    "##### Authors: Adele Zaini, Gaute Arnesson Holen, Fridtjof Gjengset\n",
    "##### Date:11. October, 2021\n",
    "\n",
    "\n",
    "## Exercise 1:\n",
    "We start by calculating the frankefunction as Described in the task. We import the following functions from the linear_regression library, which is available on github:\n",
    "\n",
    "**create_X**(x,y,n) : Creates the designmatrix with a complexity n.\n",
    "\n",
    "**Frankefunction**(x,y) : Calculates the frankefunction fro the values x and y.\n",
    "\n",
    "**Plot_frankefunction**(z,y,z) : Creates a 3d plot\n",
    "\n",
    "**Split_and_Scale**(X,z,test_size, scale) : Splits the dataset using **train_test_split** from scikit learn, into a test_size which has default value set to *0.2*. Scales the data using **StandardScalar()** if boolean argument *scale=True*(it's default value). \n",
    "\n",
    "**OLS_solver**(X_train, X_test, z_train, z_test) : Which calculates the optimal $\\hat{\\beta}$ values through matix inversion and returns these values, as well as our model $\\tilde{z}$ and out prediction. \n",
    "\n",
    "**MSE**(y_data, y_model) : Which calculates the mean square error of a dataset compared to a model or prediction.\n",
    "\n",
    "**R2**(y_data,y_model) : Which calculates the R2 score of a dataset compared to a model or prediction.\n",
    "\n",
    "After splitting the data using **Split_and_Scale()**, we find the OLS using **OLS_solver()** on the Frankefunction by matrix inversion. \n",
    "\n",
    "\n",
    "We start by simply importing the functions and creating the dataset, as well as adding some noise to the dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6df36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random, seed\n",
    "from linear_regression import FrankeFunction, create_X, Split_and_Scale, OLS_solver, MSE, R2, Plot_FrankeFunction\n",
    "\n",
    "# Create vanilla dataset:\n",
    "np.random.seed(1234)\n",
    "\n",
    "n = 25\n",
    "\n",
    "x = np.linspace(0,1,n)\n",
    "y = np.linspace(0,1,n) \n",
    "x, y = np.meshgrid(x,y)\n",
    "\n",
    "sigma_N = 0.1; mu_N = 0 \n",
    "z = FrankeFunction(x,y) +mu_N+sigma_N*np.random.randn(n,n)\n",
    "\n",
    "Plot_FrankeFunction(x,y,z, title=\"Original noisy dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffa7814",
   "metadata": {},
   "source": [
    "Above, we see a plot of the frankefunction with some added noise. Having $\\sigma = 0.1$ seems to be a reasonable amount of noise, by looking at the plot. \n",
    "\n",
    "We can know create the designmatrix, for a polynomial up to the 5th order. We also want to split and scale the dataset, so we can make our model and prediction.\n",
    "\n",
    "We do not **have** to scale this dataset as we're not working with a lot of different units. If we imagine this to be terrain data, all the data in the set could be mesured in meteres. However, we use boolean as an argument to quickly be able to enable or disable scaling. We decided to scale the data for more adaptive code that can be reused for other purposes(Adele agree?).\n",
    "\n",
    "To create the designmatrix, as well as to split and scale out data, we run the following lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41c4261",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree=5\n",
    "\n",
    "X = create_X(x, y, degree)\n",
    "X_train, X_test, z_train, z_test = Split_and_Scale(X,np.ravel(z)) #StardardScaler, test_size=0.2, scale=true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af06d7c",
   "metadata": {},
   "source": [
    "As we now have our training and test data seperated we can go on to find the optimal $\\hat{\\beta}$ values for the training set, as well as our model and prediction. We do this using **OLS_solver()** which calculates $\\hat{\\beta}$ through matrix inversion:\n",
    "\n",
    "$$\\hat{\\beta} = (X^T X)^{-1}X^T z$$\n",
    "\n",
    "Where X is the designmatrix for the traindata and z is the training datapoints from the frankefunction. To avoid problems arising from singular matrices, we use the **pinv()** function to find the psudoinverse.\n",
    "\n",
    "This yields both our model and the prediction by\n",
    "$$\\tilde{z} = X \\hat{\\beta}$$\n",
    "Where X is the designmatrix for the training data to produce our model, and the designmatrix for our test data to produce out prediction. \n",
    "\n",
    "We run the following line to find our result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3cdf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_beta, z_tilde,z_predict = OLS_solver(X_train, X_test, z_train, z_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cc3d12",
   "metadata": {},
   "source": [
    "As we now have our model and prediction we can go on to calculate the mean square error and the R2 score for both our model and presdiction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "299c597a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7050/1299271940.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrandom\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlinear_regression\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFrankeFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSplit_and_Scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOLS_solver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPlot_FrankeFunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Create vanilla dataset:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1234\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FYS-STK4155/projects/1project/linear_regression.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrandom\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Error Analysis\n",
    "prec=4\n",
    "print(\"––––––––––––––––––––––––––––––––––––––––––––\")\n",
    "print(\"Train MSE:\", np.round(MSE(z_train,z_tilde),prec))\n",
    "print(\"Test MSE:\", np.round(MSE(z_test,z_predict),prec))\n",
    "print(\"––––––––––––––––––––––––––––––––––––––––––––\")\n",
    "print(\"Train R2:\", np.round(R2(z_train,z_tilde),prec))\n",
    "print(\"Test R2:\", np.round(R2(z_test,z_predict),prec))\n",
    "print(\"––––––––––––––––––––––––––––––––––––––––––––\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821225eb",
   "metadata": {},
   "source": [
    "Finally, we know that the confidence interval of beta can be found by:\n",
    "$$var(\\beta) = \\sigma^2 (X^T X)^{-1}$$\n",
    "Where $\\sigma$ si our deviation from the dataset, and X is the designmatrix for the training data.\n",
    "\n",
    "We can therefore calculate the confidence interval in the following way:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26430cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence interval\n",
    "beta_ols_variance = sigma_N**2 * np.linalg.pinv(X_train.T @ X_train) #Calculates variance of beta\n",
    "var_diag=np.diag(beta_ols_variance)\n",
    "ci1 = ols_beta - 1.96 * np.sqrt(var_diag)/(X.shape[0])\n",
    "ci2 = ols_beta + 1.96 * np.sqrt(var_diag)/(X.shape[0])\n",
    "print('Confidence interval of β-estimator at 95 %:')\n",
    "ci_df = {r'$β_{-}$': ci1,\n",
    "         r'$β_{ols}$': ols_beta,\n",
    "         r'$β_{+}$': ci2}\n",
    "ci_df = pd.DataFrame(ci_df)\n",
    "display(np.round(ci_df,3))#prec\n",
    "print(\"––––––––––––––––––––––––––––––––––––––––––––\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51f6d6b",
   "metadata": {},
   "source": [
    "Above we can see the confidence interval for our estimators with a 95% certainty. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7327b6ff",
   "metadata": {},
   "source": [
    "\n",
    "## Exercise 2:\n",
    "\n",
    "We can reproduce figure. 2.11 from Hastie, Tibshiani and Friedman, by plotting the MSE as a function of the complexity of the model. By using the same x, y and z values, we calculate the designmatrix **X** with a complexity from n=2 to n=20, where n is the compexity/degree og the polynomial. For each designmtrix we find the OLS and calcualte the MSE for the test and training data. This produces the following plot:\n",
    "\n",
    "[insert plot]\n",
    "\n",
    "Initially the MSE for both test and train decreases as out model imporves with the complexity of the polynomial. Around a polynomial of the 5th(?) degree, we can see that the MSE for the test data increases, while the MSE for the train data continues to decrease. This is beacuse the increased complexity of the designmatrix causes overfitting. Out model therefore fits the training data better, but gives a poor model for the test data, because it has overfitted to the training set. It seems out model does best around a complexity of n=5(?)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
